07/25/2019 01:36:48 PM: log file : ./save/log/201907251336-b3aa5db9.log 
07/25/2019 01:36:48 PM: Namespace(N_turns=6, batch_size=64, d_ff=2048, debug=False, dims=512, dropout=0.1, heads=8, input_file_dir='/home/jaehoon/Git/attention_is_allyouneed/dataset/de-en/train.en', learning_rate=0.0001, model_dir='/home/jaehoon/Git/attention_is_allyouneed/jaehoon/model/', n_epochs=200, output_file_dir='/home/jaehoon/Git/attention_is_allyouneed/dataset/de-en/train.de', print_fre=100, save_log=True, sentence_model_gen='False', vocab_size=5000) 
07/25/2019 01:36:48 PM: ----- tokenize en first data ----- 
07/25/2019 01:36:48 PM: ['▁David', '▁G', 'al', 'lo', ':', '▁This', '▁is', '▁Bill', '▁La', 'n', 'ge', '.', '▁I', "'", 'm', '▁Da', 've', '▁G', 'al', 'lo', '.'] 
07/25/2019 01:36:48 PM: [2394, 378, 103, 342, 65, 111, 20, 2742, 874, 78, 419, 8, 17, 12, 45, 1485, 68, 378, 103, 342, 8] 
07/25/2019 01:36:48 PM: {} 
07/25/2019 01:37:03 PM: ----- tokenize de first data ----- 
07/25/2019 01:37:03 PM: ['▁David', '▁Gal', 'lo', ':', '▁Das', '▁ist', '▁Bill', '▁Lang', 'e', '.', '▁Ich', '▁bin', '▁Da', 've', '▁Gal', 'lo', '.'] 
07/25/2019 01:37:03 PM: [2945, 3275, 376, 43, 54, 17, 2918, 2984, 12, 8, 40, 192, 204, 911, 3275, 376, 8] 
07/25/2019 01:37:03 PM: {} 
07/25/2019 01:37:19 PM: max length of en word : 16 
07/25/2019 01:37:19 PM: max length of de word : 16 
07/25/2019 01:37:19 PM: max length of en sentence : 846 
07/25/2019 01:37:19 PM: max length of de sentence : 919 
07/25/2019 01:37:19 PM: max sentence length cutoff value 
07/25/2019 01:37:19 PM: 31 
07/25/2019 01:37:19 PM: max sentence length cutoff value 
07/25/2019 01:37:19 PM: 34 
07/25/2019 01:37:20 PM: inputs / outputs shape, first : inputs / second : outputs 
07/25/2019 01:37:20 PM: (148988, 34) 
07/25/2019 01:37:20 PM: (148988, 34) 
07/25/2019 01:38:15 PM: time = 0m, epoch 1, iter = 100, loss = 8.517, 0s per 100 iters 
07/25/2019 01:38:32 PM: time = 1m, epoch 1, iter = 200, loss = 8.517, 0s per 100 iters 
07/25/2019 01:38:50 PM: time = 1m, epoch 1, iter = 300, loss = 8.517, 0s per 100 iters 
07/25/2019 01:39:07 PM: time = 1m, epoch 1, iter = 400, loss = 8.517, 0s per 100 iters 
07/25/2019 01:39:25 PM: time = 2m, epoch 1, iter = 500, loss = 8.517, 0s per 100 iters 
07/25/2019 01:39:42 PM: time = 2m, epoch 1, iter = 600, loss = 8.517, 0s per 100 iters 
