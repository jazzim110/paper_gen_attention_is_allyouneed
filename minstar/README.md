# Transformer
Re-implementation of Attention Is All You Need

# Version Type
1. python version : 3.6.0
2. tensorflow version : 1.9.0

# References
1. sinusoidal positional encoding references: https://stackoverflow.com/questions/46452020/sinusoidal-embedding-attention-is-all-you-need
2. Multi-Head Attention references : http://nlp.seas.harvard.edu/2018/04/03/attention.html
3. Layer Normalization references : https://stackoverflow.com/questions/50973995/layer-normalization-and-how-it-works-tensorflow/52205057
4. Label Smoothing : https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.pdf
